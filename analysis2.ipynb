{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./.DS_Store\n",
      "./ds202_analysis.ipynb\n",
      "./glove.840B.300d.pkl\n",
      "./analysis2.ipynb\n",
      "./jigsaw-unintended-bias-in-toxicity-classification/test_public_expanded.csv\n",
      "./jigsaw-unintended-bias-in-toxicity-classification/identity_individual_annotations.csv\n",
      "./jigsaw-unintended-bias-in-toxicity-classification/test_private_expanded.csv\n",
      "./jigsaw-unintended-bias-in-toxicity-classification/test.csv\n",
      "./jigsaw-unintended-bias-in-toxicity-classification/all_data.csv\n",
      "./jigsaw-unintended-bias-in-toxicity-classification/toxicity_individual_annotations.csv\n",
      "./jigsaw-unintended-bias-in-toxicity-classification/train.csv\n",
      "./jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\".\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    \"jigsaw-unintended-bias-in-toxicity-classification/train.csv\"\n",
    ")\n",
    "test = pd.read_csv(\n",
    "    \"jigsaw-unintended-bias-in-toxicity-classification/test.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1804874 entries, 0 to 1804873\n",
      "Data columns (total 45 columns):\n",
      " #   Column                               Dtype  \n",
      "---  ------                               -----  \n",
      " 0   id                                   int64  \n",
      " 1   target                               float64\n",
      " 2   comment_text                         object \n",
      " 3   severe_toxicity                      float64\n",
      " 4   obscene                              float64\n",
      " 5   identity_attack                      float64\n",
      " 6   insult                               float64\n",
      " 7   threat                               float64\n",
      " 8   asian                                float64\n",
      " 9   atheist                              float64\n",
      " 10  bisexual                             float64\n",
      " 11  black                                float64\n",
      " 12  buddhist                             float64\n",
      " 13  christian                            float64\n",
      " 14  female                               float64\n",
      " 15  heterosexual                         float64\n",
      " 16  hindu                                float64\n",
      " 17  homosexual_gay_or_lesbian            float64\n",
      " 18  intellectual_or_learning_disability  float64\n",
      " 19  jewish                               float64\n",
      " 20  latino                               float64\n",
      " 21  male                                 float64\n",
      " 22  muslim                               float64\n",
      " 23  other_disability                     float64\n",
      " 24  other_gender                         float64\n",
      " 25  other_race_or_ethnicity              float64\n",
      " 26  other_religion                       float64\n",
      " 27  other_sexual_orientation             float64\n",
      " 28  physical_disability                  float64\n",
      " 29  psychiatric_or_mental_illness        float64\n",
      " 30  transgender                          float64\n",
      " 31  white                                float64\n",
      " 32  created_date                         object \n",
      " 33  publication_id                       int64  \n",
      " 34  parent_id                            float64\n",
      " 35  article_id                           int64  \n",
      " 36  rating                               object \n",
      " 37  funny                                int64  \n",
      " 38  wow                                  int64  \n",
      " 39  sad                                  int64  \n",
      " 40  likes                                int64  \n",
      " 41  disagree                             int64  \n",
      " 42  sexual_explicit                      float64\n",
      " 43  identity_annotator_count             int64  \n",
      " 44  toxicity_annotator_count             int64  \n",
      "dtypes: float64(32), int64(10), object(3)\n",
      "memory usage: 619.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train.sample(frac=0.1, random_state=42, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:50: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:78: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:50: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:78: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/7g/f8wv1hz96056pmbvhy90v0n80000gn/T/ipykernel_33787/2321238962.py:50: SyntaxWarning: invalid escape sequence '\\['\n",
      "  text = re.sub(\"\\[[^]]*\\]\", \"\", text)\n",
      "/var/folders/7g/f8wv1hz96056pmbvhy90v0n80000gn/T/ipykernel_33787/2321238962.py:78: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  text = re.sub(\"\\d\", \"num\", text)\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup  # Text Cleaning\n",
    "import re, string  # Regular Expressions, String\n",
    "from nltk.corpus import stopwords  # stopwords\n",
    "from nltk.stem.porter import PorterStemmer  # for word stemming\n",
    "from nltk.stem import WordNetLemmatizer  # for word lemmatization\n",
    "import unicodedata\n",
    "import html\n",
    "\n",
    "# set of stopwords to be removed from text\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "# update stopwords to have punctuation too\n",
    "stop.update(list(string.punctuation))\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # Remove unwanted html characters\n",
    "    re1 = re.compile(r\"  +\")\n",
    "    x1 = (\n",
    "        text.lower()\n",
    "        .replace(\"#39;\", \"'\")\n",
    "        .replace(\"amp;\", \"&\")\n",
    "        .replace(\"#146;\", \"'\")\n",
    "        .replace(\"nbsp;\", \" \")\n",
    "        .replace(\"#36;\", \"$\")\n",
    "        .replace(\"\\\\n\", \"\\n\")\n",
    "        .replace(\"quot;\", \"'\")\n",
    "        .replace(\"<br />\", \"\\n\")\n",
    "        .replace('\\\\\"', '\"')\n",
    "        .replace(\"<unk>\", \"u_n\")\n",
    "        .replace(\" @.@ \", \".\")\n",
    "        .replace(\" @-@ \", \"-\")\n",
    "        .replace(\"\\\\\", \" \\\\ \")\n",
    "    )\n",
    "    text = re1.sub(\" \", html.unescape(x1))\n",
    "\n",
    "    # remove non-ascii characters\n",
    "    text = (\n",
    "        unicodedata.normalize(\"NFKD\", text)\n",
    "        .encode(\"ascii\", \"ignore\")\n",
    "        .decode(\"utf-8\", \"ignore\")\n",
    "    )\n",
    "\n",
    "    #     # strip html\n",
    "    #     soup = BeautifulSoup(text, 'html.parser')\n",
    "    #     text = soup.get_text()\n",
    "\n",
    "    # remove between square brackets\n",
    "    text = re.sub(\"\\[[^]]*\\]\", \"\", text)\n",
    "\n",
    "    # remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # remove twitter tags\n",
    "    text = text.replace(\"@\", \"\")\n",
    "\n",
    "    # remove hashtags\n",
    "    text = text.replace(\"#\", \"\")\n",
    "\n",
    "    # remove all non-alphabetic characters\n",
    "    text = re.sub(r\"[^a-zA-Z ]\", \"\", text)\n",
    "\n",
    "    # remove stopwords from text\n",
    "    final_text = []\n",
    "    for word in text.split():\n",
    "        if word.strip().lower() not in stop:\n",
    "            final_text.append(word.strip().lower())\n",
    "\n",
    "    text = \" \".join(final_text)\n",
    "\n",
    "    # lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    text = \" \".join([lemmatizer.lemmatize(word, pos=\"v\") for word in text.split()])\n",
    "\n",
    "    # replace all numbers with \"num\"\n",
    "    text = re.sub(\"\\d\", \"num\", text)\n",
    "\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train\n",
    "train_data[\"threat\"] = np.where(train_data[\"threat\"] >= 0.25, 1, 0)\n",
    "train_data[\"severe_toxicity\"] = np.where(train_data[\"severe_toxicity\"] >= 0.25, 1, 0)\n",
    "train_data[\"insult\"] = np.where(train_data[\"insult\"] >= 0.25, 1, 0)\n",
    "train_data[\"obscene\"] = np.where(train_data[\"obscene\"] >= 0.25, 1, 0)\n",
    "train_data[\"identity_attack\"] = np.where(train_data[\"identity_attack\"] >= 0.25, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = [\n",
    "    \"comment_text\",\n",
    "    \"target\",\n",
    "    \"severe_toxicity\",\n",
    "    \"obscene\",\n",
    "    \"threat\",\n",
    "    \"insult\",\n",
    "    \"identity_attack\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ur a sh*tty comment.</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>It's ridiculous that these guys are being call...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This story gets more ridiculous by the hour! A...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Angry trolls, misogynists and Racists\", oh my....</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         comment_text    target  \\\n",
       "4                haha you guys are a bunch of losers.  0.893617   \n",
       "5                                ur a sh*tty comment.  0.666667   \n",
       "13  It's ridiculous that these guys are being call...  0.600000   \n",
       "14  This story gets more ridiculous by the hour! A...  0.500000   \n",
       "19  Angry trolls, misogynists and Racists\", oh my....  0.500000   \n",
       "\n",
       "    severe_toxicity  obscene  threat  insult  identity_attack  \n",
       "4                 0        0       0       1                0  \n",
       "5                 0        1       0       1                0  \n",
       "13                0        0       0       1                0  \n",
       "14                0        0       0       1                0  \n",
       "19                0        0       0       1                0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_final = train_data[possible_labels]\n",
    "train_data_final = train_data_final[(train_data_final[\"target\"] >= 0.5)]\n",
    "train_data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels1 = [\"severe_toxicity\", \"obscene\", \"threat\", \"insult\", \"identity_attack\"]\n",
    "targets = train_data_final[possible_labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_final[\"clean_comment_text\"] = train_data_final[\"comment_text\"].apply(\n",
    "    clean_text\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>target</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>clean_comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>haha guy bunch loser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ur a sh*tty comment.</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ur shtty comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>It's ridiculous that these guys are being call...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ridiculous guy call protester arm threat viole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This story gets more ridiculous by the hour! A...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>story get ridiculous hour love people send guy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Angry trolls, misogynists and Racists\", oh my....</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>angry troll misogynist racist oh doesnt take i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         comment_text    target  \\\n",
       "4                haha you guys are a bunch of losers.  0.893617   \n",
       "5                                ur a sh*tty comment.  0.666667   \n",
       "13  It's ridiculous that these guys are being call...  0.600000   \n",
       "14  This story gets more ridiculous by the hour! A...  0.500000   \n",
       "19  Angry trolls, misogynists and Racists\", oh my....  0.500000   \n",
       "\n",
       "    severe_toxicity  obscene  threat  insult  identity_attack  \\\n",
       "4                 0        0       0       1                0   \n",
       "5                 0        1       0       1                0   \n",
       "13                0        0       0       1                0   \n",
       "14                0        0       0       1                0   \n",
       "19                0        0       0       1                0   \n",
       "\n",
       "                                   clean_comment_text  \n",
       "4                                haha guy bunch loser  \n",
       "5                                    ur shtty comment  \n",
       "13  ridiculous guy call protester arm threat viole...  \n",
       "14  story get ridiculous hour love people send guy...  \n",
       "19  angry troll misogynist racist oh doesnt take i...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.03073e+05, 2.78780e+04, 1.18550e+04, 1.52700e+03, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00]),\n",
       " array([  0. ,  30.4,  60.8,  91.2, 121.6, 152. , 182.4, 212.8, 243.2,\n",
       "        273.6, 304. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(list(train_data_final[\"clean_comment_text\"].str.split().map(lambda x: len(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(\n",
    "    np.array(train_data_final[\"clean_comment_text\"].str.split().map(lambda x: len(x)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dict = pd.read_pickle(\n",
    "    \"tokenizer.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (144334, 18)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Setting up the tokenizer\n",
    "vocab_size = 10000\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"UNK\")\n",
    "tokenizer.fit_on_texts(list(train_data_final[\"clean_comment_text\"]))\n",
    "\n",
    "max_len = 18\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_data_final[\"clean_comment_text\"])\n",
    "\n",
    "X_train_seq = pad_sequences(\n",
    "    X_train_seq, maxlen=max_len, truncating=\"post\", padding=\"post\"\n",
    ")\n",
    "# X_test_seq = pad_sequences(X_test_seq, maxlen = max_len, truncating = 'post', padding = 'post')\n",
    "\n",
    "\n",
    "print(f\"X_train shape: {X_train_seq.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (144334, 5)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(train_data_final[possible_labels1]).astype(int)\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (115467, 18)\n",
      "X_val shape: (28867, 18)\n",
      "y_train shape: (115467, 5)\n",
      "y_val shape: (28867, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_seq, X_val_seq, y_train, y_val = train_test_split(\n",
    "    X_train_seq, y_train, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train_seq.shape}\")\n",
    "print(f\"X_val shape: {X_val_seq.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 135845\n"
     ]
    }
   ],
   "source": [
    "num_words = len(tokenizer.word_index)\n",
    "print(f\"Number of unique words: {num_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135845, 300)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((num_words, 300))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < num_words:\n",
    "        emb_vec = embedding_dict.get(word)\n",
    "        if emb_vec is not None:\n",
    "            embedding_matrix[i] = emb_vec\n",
    "\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "def setup_lstm_model(max_len, n_latent_factors):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        layers.Embedding(\n",
    "            num_words,\n",
    "            n_latent_factors,\n",
    "            weights=[embedding_matrix],\n",
    "            input_length=max_len,\n",
    "            trainable=False,\n",
    "        )\n",
    "    )\n",
    "    model.add(layers.LSTM(units=max_len, return_sequences=True))\n",
    "    model.add(layers.GlobalAveragePooling1D())\n",
    "    model.add(layers.Dense(units=5, activation=\"sigmoid\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulganesan/.pyenv/versions/3.12.2/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">40,753,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │    \u001b[38;5;34m40,753,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_2      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,753,500</span> (155.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,753,500\u001b[0m (155.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,753,500</span> (155.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m40,753,500\u001b[0m (155.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_model = setup_lstm_model(max_len=max_len, n_latent_factors=300)\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.7379 - loss: 0.3089 - val_accuracy: 0.7572 - val_loss: 0.1988\n",
      "Epoch 2/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7595 - loss: 0.1922 - val_accuracy: 0.7676 - val_loss: 0.1825\n",
      "Epoch 3/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7674 - loss: 0.1802 - val_accuracy: 0.7732 - val_loss: 0.1767\n",
      "Epoch 4/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7711 - loss: 0.1724 - val_accuracy: 0.7755 - val_loss: 0.1735\n",
      "Epoch 5/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.1684 - val_accuracy: 0.7793 - val_loss: 0.1718\n",
      "Epoch 6/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7772 - loss: 0.1651 - val_accuracy: 0.7773 - val_loss: 0.1704\n",
      "Epoch 7/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7781 - loss: 0.1636 - val_accuracy: 0.7764 - val_loss: 0.1699\n",
      "Epoch 8/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7801 - loss: 0.1616 - val_accuracy: 0.7830 - val_loss: 0.1695\n",
      "Epoch 9/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7840 - loss: 0.1587 - val_accuracy: 0.7817 - val_loss: 0.1688\n",
      "Epoch 10/10\n",
      "\u001b[1m903/903\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7809 - loss: 0.1598 - val_accuracy: 0.7809 - val_loss: 0.1692\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x300e031d0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "lstm_model.fit(\n",
    "    X_train_seq,\n",
    "    y_train,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_val_seq, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "lstm_model.history.history\n",
    "lstm_model.save(\"lstm_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy is  : 0.7815219759941101\n",
      "Validation Accuracy is: 0.7829701900482178\n"
     ]
    }
   ],
   "source": [
    "plt.plot(lstm_model.history.history[\"accuracy\"], label=\"acc\")\n",
    "plt.plot(lstm_model.history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training Accuracy is  :\", max(lstm_model.history.history[\"accuracy\"]))\n",
    "print(\"Validation Accuracy is:\", max(lstm_model.history.history[\"val_accuracy\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Subgroup Analysis Results:\n",
      "{'LGBTQ+': {'True': 0.5, 'Predicted': 0}, 'Black': {'True': 0, 'Predicted': 0}, 'Lesbian': {'True': 0, 'Predicted': 0}, 'White': {'True': 0, 'Predicted': 1}, 'Neutral': {'True': 0, 'Predicted': 0}, 'Negative': {'True': 1, 'Predicted': 0}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example comments with identity terms\n",
    "identity_comments = [\n",
    "    \"I think gay people are great.\",\n",
    "    \"Black people are so talented.\",\n",
    "    \"Lesbian rights are important.\",\n",
    "    \"White people need to be respected.\",\n",
    "    \"I love this!\",\n",
    "    \"I hate this!\",\n",
    "]\n",
    "\n",
    "# Labels representing if a comment is toxic (1) or non-toxic (0)\n",
    "# Adjust these labels based on your dataset\n",
    "identity_comments_labels = [0.5, 0, 0, 0, 0, 1]\n",
    "\n",
    "# Tokenize and pad identity comments\n",
    "identity_comments_sequences = tokenizer.texts_to_sequences(identity_comments)\n",
    "identity_comments_padded = pad_sequences(identity_comments_sequences, maxlen=max_len)\n",
    "\n",
    "# Get model predictions\n",
    "identity_comments_predictions = lstm_model.predict(identity_comments_padded)\n",
    "identity_comments_predictions = (\n",
    "    (identity_comments_predictions > 0.5).astype(int).flatten()\n",
    ")\n",
    "\n",
    "# Calculate accuracy per subgroup\n",
    "accuracy_per_subgroup = {}\n",
    "subgroups = [\"LGBTQ+\", \"Black\", \"Lesbian\", \"White\", \"Neutral\", \"Negative\"]\n",
    "for subgroup, true_label, predicted_label in zip(\n",
    "    subgroups, identity_comments_labels, identity_comments_predictions\n",
    "):\n",
    "    accuracy_per_subgroup[subgroup] = {\"True\": true_label, \"Predicted\": predicted_label}\n",
    "\n",
    "print(\"Subgroup Analysis Results:\")\n",
    "print(accuracy_per_subgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7070/7070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n",
      "Comment 1: haha you guys are a bunch of losers.\n",
      "Predicted: Non-Toxic, Actual: Toxic\n",
      "\n",
      "Comment 2: This is a great story. Man. I wonder if the person who yelled \"shut the fuck up!\" at him ever heard it.\n",
      "Predicted: Non-Toxic, Actual: Non-Toxic\n",
      "\n",
      "Comment 3: Yet call out all Muslims for the acts of a few will get you pilloried.   So why is it okay to smear an entire religion over these few idiots?  Or is this because it's okay to bash Christian sects?\n",
      "Predicted: Non-Toxic, Actual: Toxic\n",
      "\n",
      "Comment 4: This bitch is nuts. Who would read a book by a woman.\n",
      "Predicted: Toxic, Actual: Toxic\n",
      "\n",
      "Comment 5: Mormons have had a complicated relationship with federal law.\n",
      "Predicted: Non-Toxic, Actual: Non-Toxic\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tokenization\n",
    "identity_comments_sequences = tokenizer.texts_to_sequences(identity_comments_texts)\n",
    "identity_comments_padded = pad_sequences(identity_comments_sequences, maxlen=max_len)\n",
    "\n",
    "# Prediction\n",
    "identity_comments_predictions = lstm_model.predict(identity_comments_padded)\n",
    "identity_comments_predictions = (\n",
    "    (identity_comments_predictions > 0.5).astype(int).flatten()\n",
    ")\n",
    "\n",
    "# Analysis Example\n",
    "accuracy_per_subgroup = {}\n",
    "for i, comment in enumerate(identity_comments_texts[:5]):\n",
    "    predicted = \"Toxic\" if identity_comments_predictions[i] else \"Non-Toxic\"\n",
    "    actual = \"Toxic\" if identity_comments_labels[i] else \"Non-Toxic\"\n",
    "    print(f\"Comment {i+1}: {comment}\\nPredicted: {predicted}, Actual: {actual}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7070/7070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Inconsistent sample count: 226234 labels vs. 1131170 predictions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 62\u001b[0m\n\u001b[1;32m     57\u001b[0m identity_comments_predictions \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     58\u001b[0m     (identity_comments_predictions \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Ensure consistent number of labels and predictions\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(identity_comments_labels) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m     63\u001b[0m     identity_comments_predictions\n\u001b[1;32m     64\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInconsistent sample count: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(identity_comments_labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m labels vs. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(identity_comments_predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m predictions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Overall Metrics\u001b[39;00m\n\u001b[1;32m     67\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(identity_comments_labels, identity_comments_predictions)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Inconsistent sample count: 226234 labels vs. 1131170 predictions."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "# Load your dataset\n",
    "train_data_path = \"train.csv\"  # Replace with the actual path to your CSV file\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "\n",
    "# List of identity columns based on your dataset\n",
    "identity_columns = [\n",
    "    \"asian\",\n",
    "    \"atheist\",\n",
    "    \"bisexual\",\n",
    "    \"black\",\n",
    "    \"buddhist\",\n",
    "    \"christian\",\n",
    "    \"female\",\n",
    "    \"heterosexual\",\n",
    "    \"hindu\",\n",
    "    \"homosexual_gay_or_lesbian\",\n",
    "    \"intellectual_or_learning_disability\",\n",
    "    \"jewish\",\n",
    "    \"latino\",\n",
    "    \"male\",\n",
    "    \"muslim\",\n",
    "    \"other_disability\",\n",
    "    \"other_gender\",\n",
    "    \"other_race_or_ethnicity\",\n",
    "    \"other_religion\",\n",
    "    \"other_sexual_orientation\",\n",
    "    \"physical_disability\",\n",
    "    \"psychiatric_or_mental_illness\",\n",
    "    \"transgender\",\n",
    "    \"white\",\n",
    "]\n",
    "\n",
    "# Extract identity comments and their target labels\n",
    "identity_comments = train_data[(train_data[identity_columns] > 0).any(axis=1)]\n",
    "identity_comments_labels = (\n",
    "    identity_comments[\"target\"].apply(lambda x: 1 if x >= 0.5 else 0).values\n",
    ")\n",
    "identity_comments_texts = identity_comments[\"comment_text\"].values\n",
    "\n",
    "# Tokenization and Padding\n",
    "identity_comments_sequences = tokenizer.texts_to_sequences(identity_comments_texts)\n",
    "identity_comments_padded = pad_sequences(identity_comments_sequences, maxlen=max_len)\n",
    "\n",
    "# Prediction\n",
    "identity_comments_predictions = lstm_model.predict(identity_comments_padded).squeeze()\n",
    "identity_comments_predictions = (\n",
    "    (identity_comments_predictions > 0.5).astype(int).flatten()\n",
    ")\n",
    "\n",
    "# Overall Metrics\n",
    "accuracy = accuracy_score(identity_comments_labels, identity_comments_predictions)\n",
    "precision = precision_score(identity_comments_labels, identity_comments_predictions)\n",
    "recall = recall_score(identity_comments_labels, identity_comments_predictions)\n",
    "f1 = f1_score(identity_comments_labels, identity_comments_predictions)\n",
    "\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "\n",
    "# Function to compute FPR and FNR\n",
    "def compute_fpr_fnr(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    return fpr, fnr\n",
    "\n",
    "\n",
    "# Subgroup Analysis\n",
    "subgroup_metrics = {}\n",
    "for col in identity_columns:\n",
    "    subgroup_data = identity_comments[identity_comments[col] > 0]\n",
    "    subgroup_labels = (\n",
    "        subgroup_data[\"target\"].apply(lambda x: 1 if x >= 0.5 else 0).values\n",
    "    )\n",
    "    subgroup_texts = subgroup_data[\"comment_text\"].values\n",
    "\n",
    "    # Tokenize and pad subgroup comments\n",
    "    subgroup_sequences = tokenizer.texts_to_sequences(subgroup_texts)\n",
    "    subgroup_padded = pad_sequences(subgroup_sequences, maxlen=max_len)\n",
    "\n",
    "    # Predict using the model\n",
    "    subgroup_predictions = lstm_model.predict(subgroup_padded).squeeze()\n",
    "    subgroup_predictions = (subgroup_predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "    # Calculate subgroup metrics\n",
    "    acc = accuracy_score(subgroup_labels, subgroup_predictions)\n",
    "    precision = precision_score(subgroup_labels, subgroup_predictions, zero_division=0)\n",
    "    recall = recall_score(subgroup_labels, subgroup_predictions, zero_division=0)\n",
    "    f1 = f1_score(subgroup_labels, subgroup_predictions, zero_division=0)\n",
    "    fpr, fnr = compute_fpr_fnr(subgroup_labels, subgroup_predictions)\n",
    "\n",
    "    subgroup_metrics[col] = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"False Positive Rate\": fpr,\n",
    "        \"False Negative Rate\": fnr,\n",
    "    }\n",
    "\n",
    "# Display subgroup metrics\n",
    "print(\"\\nSubgroup Analysis Results:\")\n",
    "for col, metrics in subgroup_metrics.items():\n",
    "    print(f\"\\nSubgroup: {col.capitalize()}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.2f}\")\n",
    "\n",
    "# Compute Disparate Impact Ratio\n",
    "reference_group = \"white\"  # Adjust to the appropriate reference group in your dataset\n",
    "reference_group_data = identity_comments[identity_comments[reference_group] > 0]\n",
    "reference_group_labels = (\n",
    "    reference_group_data[\"target\"].apply(lambda x: 1 if x >= 0.5 else 0).values\n",
    ")\n",
    "reference_group_sequences = tokenizer.texts_to_sequences(\n",
    "    reference_group_data[\"comment_text\"].values\n",
    ")\n",
    "reference_group_padded = pad_sequences(reference_group_sequences, maxlen=max_len)\n",
    "reference_group_predictions = lstm_model.predict(reference_group_padded).squeeze()\n",
    "reference_group_predictions = (reference_group_predictions > 0.5).astype(int).flatten()\n",
    "reference_group_rate = reference_group_predictions.mean()\n",
    "\n",
    "dir_metrics = {}\n",
    "for col in identity_columns:\n",
    "    subgroup_data = identity_comments[identity_comments[col] > 0]\n",
    "    subgroup_predictions = lstm_model.predict(\n",
    "        pad_sequences(\n",
    "            tokenizer.texts_to_sequences(subgroup_data[\"comment_text\"].values),\n",
    "            maxlen=max_len,\n",
    "        )\n",
    "    ).squeeze()\n",
    "    subgroup_predictions = (subgroup_predictions > 0.5).astype(int).flatten()\n",
    "    subgroup_rate = subgroup_predictions.mean()\n",
    "    dir_metrics[col] = (\n",
    "        subgroup_rate / reference_group_rate if reference_group_rate > 0 else 0\n",
    "    )\n",
    "\n",
    "print(\"\\nDisparate Impact Ratio:\")\n",
    "for col, ratio in dir_metrics.items():\n",
    "    print(f\"{col.capitalize()}: {ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "comment = train_df['comment_text'][0]\n",
    "print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "[[0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00528709 0.09826894 0.01792004 0.920469   0.02300737]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00528709 0.09826896 0.01792004 0.920469   0.02300737]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00528709 0.09826896 0.01792004 0.920469   0.02300737]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00528709 0.09826896 0.01792004 0.920469   0.02300737]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00528709 0.09826894 0.01792004 0.920469   0.02300737]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00528709 0.09826896 0.01792004 0.920469   0.02300737]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705872 0.9235639  0.01970613]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418706 0.0179998  0.919832   0.02180906]\n",
      " [0.00543064 0.09418707 0.0179998  0.919832   0.02180906]\n",
      " [0.00502831 0.090804   0.01705873 0.9235639  0.01970613]]\n"
     ]
    }
   ],
   "source": [
    "    tokenized = tokenizer.texts_to_sequences(comment)\n",
    "    padded = pad_sequences(tokenized, maxlen=max_len)\n",
    "\n",
    "    # Predict using the model\n",
    "    predict = lstm_model.predict(padded).squeeze()\n",
    "    print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Shape of raw predictions: (1, 5)\n",
      "Raw predictions: [[0.00791783 0.10389546 0.03198377 0.91358393 0.05306262]]\n",
      "Aggregated Predictions (Mean): [0.00791783 0.10389546 0.03198377 0.91358393 0.05306262]\n",
      "Binary Predictions: [0 0 0 1 0]\n",
      "Multi-Class Prediction (Argmax): 3\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Example comment\n",
    "comment = [\"This is a sample comment for testing\"]\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenized = tokenizer.texts_to_sequences(comment)\n",
    "padded = pad_sequences(tokenized, maxlen=max_len)\n",
    "\n",
    "# Predict using the model\n",
    "raw_predictions = lstm_model.predict(padded)\n",
    "\n",
    "# Inspect the shape of the predictions\n",
    "print(\"Shape of raw predictions:\", raw_predictions.shape)\n",
    "print(\"Raw predictions:\", raw_predictions)\n",
    "\n",
    "# Aggregating predictions by averaging over the sequence (e.g., mean)\n",
    "aggregated_predictions = np.mean(raw_predictions, axis=0)\n",
    "\n",
    "# For binary classification, consider the probabilities directly\n",
    "binary_predictions = (aggregated_predictions > 0.5).astype(int)\n",
    "\n",
    "print(\"Aggregated Predictions (Mean):\", aggregated_predictions)\n",
    "print(\"Binary Predictions:\", binary_predictions)\n",
    "\n",
    "# If it's a multi-class problem, choose the class with the highest probability\n",
    "multi_class_predictions = np.argmax(aggregated_predictions)\n",
    "\n",
    "print(\"Multi-Class Prediction (Argmax):\", multi_class_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Shape of raw predictions: (1, 5)\n",
      "Raw predictions: [[0.00791783 0.10389546 0.03198377 0.91358393 0.05306262]]\n",
      "Binary Predictions: [[0 0 0 1 0]]\n",
      "Multi-Class Prediction (Argmax): [3]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Example comment\n",
    "comment = [\"This is a sample comment for testing\"]\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenized = tokenizer.texts_to_sequences(comment)\n",
    "padded = pad_sequences(tokenized, maxlen=max_len)\n",
    "\n",
    "# Predict using the model\n",
    "raw_predictions = lstm_model.predict(padded)\n",
    "\n",
    "# Inspect the shape of the predictions\n",
    "print(\"Shape of raw predictions:\", raw_predictions.shape)\n",
    "print(\"Raw predictions:\", raw_predictions)\n",
    "\n",
    "# For multi-label classification, consider each probability directly\n",
    "binary_predictions = (raw_predictions > 0.5).astype(int)\n",
    "\n",
    "print(\"Binary Predictions:\", binary_predictions)\n",
    "\n",
    "# If it's a multi-class problem (one-hot encoded output), choose the class with the highest probability\n",
    "multi_class_predictions = np.argmax(raw_predictions, axis=1)\n",
    "\n",
    "print(\"Multi-Class Prediction (Argmax):\", multi_class_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7070/7070\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step\n",
      "\n",
      "Overall Metrics:\n",
      "Accuracy: 0.15\n",
      "Precision: 0.15\n",
      "Recall: 1.00\n",
      "F1 Score: 0.26\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m1918/1918\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m2303/2303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m833/833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m936/936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "Subgroup Analysis Results:\n",
      "\n",
      "Subgroup: Asian\n",
      "Accuracy: 0.11\n",
      "Precision: 0.11\n",
      "Recall: 1.00\n",
      "F1 Score: 0.20\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Atheist\n",
      "Accuracy: 0.12\n",
      "Precision: 0.12\n",
      "Recall: 1.00\n",
      "F1 Score: 0.22\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Bisexual\n",
      "Accuracy: 0.16\n",
      "Precision: 0.16\n",
      "Recall: 1.00\n",
      "F1 Score: 0.27\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Black\n",
      "Accuracy: 0.28\n",
      "Precision: 0.28\n",
      "Recall: 1.00\n",
      "F1 Score: 0.44\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Buddhist\n",
      "Accuracy: 0.12\n",
      "Precision: 0.12\n",
      "Recall: 1.00\n",
      "F1 Score: 0.21\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Christian\n",
      "Accuracy: 0.09\n",
      "Precision: 0.09\n",
      "Recall: 1.00\n",
      "F1 Score: 0.16\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Female\n",
      "Accuracy: 0.14\n",
      "Precision: 0.14\n",
      "Recall: 1.00\n",
      "F1 Score: 0.25\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Heterosexual\n",
      "Accuracy: 0.21\n",
      "Precision: 0.21\n",
      "Recall: 1.00\n",
      "F1 Score: 0.34\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Hindu\n",
      "Accuracy: 0.13\n",
      "Precision: 0.13\n",
      "Recall: 1.00\n",
      "F1 Score: 0.22\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Homosexual_gay_or_lesbian\n",
      "Accuracy: 0.25\n",
      "Precision: 0.25\n",
      "Recall: 1.00\n",
      "F1 Score: 0.40\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Intellectual_or_learning_disability\n",
      "Accuracy: 0.31\n",
      "Precision: 0.31\n",
      "Recall: 1.00\n",
      "F1 Score: 0.48\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Jewish\n",
      "Accuracy: 0.15\n",
      "Precision: 0.15\n",
      "Recall: 1.00\n",
      "F1 Score: 0.26\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Latino\n",
      "Accuracy: 0.16\n",
      "Precision: 0.16\n",
      "Recall: 1.00\n",
      "F1 Score: 0.28\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Male\n",
      "Accuracy: 0.15\n",
      "Precision: 0.15\n",
      "Recall: 1.00\n",
      "F1 Score: 0.26\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Muslim\n",
      "Accuracy: 0.21\n",
      "Precision: 0.21\n",
      "Recall: 1.00\n",
      "F1 Score: 0.35\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Other_disability\n",
      "Accuracy: 0.13\n",
      "Precision: 0.13\n",
      "Recall: 1.00\n",
      "F1 Score: 0.23\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Other_gender\n",
      "Accuracy: 0.16\n",
      "Precision: 0.16\n",
      "Recall: 1.00\n",
      "F1 Score: 0.27\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Other_race_or_ethnicity\n",
      "Accuracy: 0.14\n",
      "Precision: 0.14\n",
      "Recall: 1.00\n",
      "F1 Score: 0.25\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Other_religion\n",
      "Accuracy: 0.12\n",
      "Precision: 0.12\n",
      "Recall: 1.00\n",
      "F1 Score: 0.22\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Other_sexual_orientation\n",
      "Accuracy: 0.18\n",
      "Precision: 0.18\n",
      "Recall: 1.00\n",
      "F1 Score: 0.30\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Physical_disability\n",
      "Accuracy: 0.14\n",
      "Precision: 0.14\n",
      "Recall: 1.00\n",
      "F1 Score: 0.24\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Psychiatric_or_mental_illness\n",
      "Accuracy: 0.23\n",
      "Precision: 0.23\n",
      "Recall: 1.00\n",
      "F1 Score: 0.37\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: Transgender\n",
      "Accuracy: 0.18\n",
      "Precision: 0.18\n",
      "Recall: 1.00\n",
      "F1 Score: 0.30\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\n",
      "Subgroup: White\n",
      "Accuracy: 0.26\n",
      "Precision: 0.26\n",
      "Recall: 1.00\n",
      "F1 Score: 0.41\n",
      "False Positive Rate: 1.00\n",
      "False Negative Rate: 0.00\n",
      "\u001b[1m936/936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m343/343\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m612/612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m1918/1918\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n",
      "\u001b[1m2303/2303\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m108/108\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m479/479\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m217/217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m2506/2506\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n",
      "\u001b[1m833/833\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m590/590\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m523/523\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m192/192\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m936/936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "\n",
      "Disparate Impact Ratio:\n",
      "Asian: 1.00\n",
      "Atheist: 1.00\n",
      "Bisexual: 1.00\n",
      "Black: 1.00\n",
      "Buddhist: 1.00\n",
      "Christian: 1.00\n",
      "Female: 1.00\n",
      "Heterosexual: 1.00\n",
      "Hindu: 1.00\n",
      "Homosexual_gay_or_lesbian: 1.00\n",
      "Intellectual_or_learning_disability: 1.00\n",
      "Jewish: 1.00\n",
      "Latino: 1.00\n",
      "Male: 1.00\n",
      "Muslim: 1.00\n",
      "Other_disability: 1.00\n",
      "Other_gender: 1.00\n",
      "Other_race_or_ethnicity: 1.00\n",
      "Other_religion: 1.00\n",
      "Other_sexual_orientation: 1.00\n",
      "Physical_disability: 1.00\n",
      "Psychiatric_or_mental_illness: 1.00\n",
      "Transgender: 1.00\n",
      "White: 1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "# Load the dataset\n",
    "train_data_path = \"train.csv\"  # Replace with the actual path to your CSV file\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "\n",
    "# List of identity columns based on your dataset\n",
    "identity_columns = [\n",
    "    \"asian\",\n",
    "    \"atheist\",\n",
    "    \"bisexual\",\n",
    "    \"black\",\n",
    "    \"buddhist\",\n",
    "    \"christian\",\n",
    "    \"female\",\n",
    "    \"heterosexual\",\n",
    "    \"hindu\",\n",
    "    \"homosexual_gay_or_lesbian\",\n",
    "    \"intellectual_or_learning_disability\",\n",
    "    \"jewish\",\n",
    "    \"latino\",\n",
    "    \"male\",\n",
    "    \"muslim\",\n",
    "    \"other_disability\",\n",
    "    \"other_gender\",\n",
    "    \"other_race_or_ethnicity\",\n",
    "    \"other_religion\",\n",
    "    \"other_sexual_orientation\",\n",
    "    \"physical_disability\",\n",
    "    \"psychiatric_or_mental_illness\",\n",
    "    \"transgender\",\n",
    "    \"white\",\n",
    "]\n",
    "\n",
    "# Extract identity comments and their target labels\n",
    "identity_comments = train_data[(train_data[identity_columns] > 0).any(axis=1)]\n",
    "identity_comments_labels = (\n",
    "    identity_comments[\"target\"].apply(lambda x: 1 if x >= 0.5 else 0).values\n",
    ")\n",
    "identity_comments_texts = identity_comments[\"comment_text\"].values\n",
    "\n",
    "# Tokenization and Padding\n",
    "identity_comments_sequences = tokenizer.texts_to_sequences(identity_comments_texts)\n",
    "identity_comments_padded = pad_sequences(identity_comments_sequences, maxlen=max_len)\n",
    "\n",
    "# Predict using the model (multi-label)\n",
    "raw_predictions = lstm_model.predict(identity_comments_padded)\n",
    "\n",
    "# Index mapping for the five classes\n",
    "class_indices = {\n",
    "    \"severe_toxicity\": 0,\n",
    "    \"obscene\": 1,\n",
    "    \"threat\": 2,\n",
    "    \"insult\": 3,\n",
    "    \"identity_attack\": 4,\n",
    "}\n",
    "\n",
    "# Aggregate binary predictions for overall toxicity (e.g., insult class)\n",
    "binary_predictions = (raw_predictions[:, class_indices[\"insult\"]] > 0.5).astype(int)\n",
    "\n",
    "# Ensure consistent number of labels and predictions\n",
    "assert len(identity_comments_labels) == len(\n",
    "    binary_predictions\n",
    "), f\"Inconsistent sample count: {len(identity_comments_labels)} labels vs. {len(binary_predictions)} predictions.\"\n",
    "\n",
    "# Overall Metrics\n",
    "accuracy = accuracy_score(identity_comments_labels, binary_predictions)\n",
    "precision = precision_score(\n",
    "    identity_comments_labels, binary_predictions, zero_division=0\n",
    ")\n",
    "recall = recall_score(identity_comments_labels, binary_predictions, zero_division=0)\n",
    "f1 = f1_score(identity_comments_labels, binary_predictions, zero_division=0)\n",
    "\n",
    "print(\"\\nOverall Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "\n",
    "# Function to compute FPR and FNR\n",
    "def compute_fpr_fnr(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    return fpr, fnr\n",
    "\n",
    "\n",
    "# Subgroup Analysis\n",
    "subgroup_metrics = {}\n",
    "for col in identity_columns:\n",
    "    subgroup_data = identity_comments[identity_comments[col] > 0]\n",
    "    subgroup_labels = (\n",
    "        subgroup_data[\"target\"].apply(lambda x: 1 if x >= 0.5 else 0).values\n",
    "    )\n",
    "    subgroup_texts = subgroup_data[\"comment_text\"].values\n",
    "\n",
    "    # Tokenize and pad subgroup comments\n",
    "    subgroup_sequences = tokenizer.texts_to_sequences(subgroup_texts)\n",
    "    subgroup_padded = pad_sequences(subgroup_sequences, maxlen=max_len)\n",
    "\n",
    "    # Predict using the model\n",
    "    subgroup_raw_predictions = lstm_model.predict(subgroup_padded)\n",
    "    subgroup_predictions = (\n",
    "        subgroup_raw_predictions[:, class_indices[\"insult\"]] > 0.5\n",
    "    ).astype(int)\n",
    "\n",
    "    # Calculate subgroup metrics\n",
    "    acc = accuracy_score(subgroup_labels, subgroup_predictions)\n",
    "    precision = precision_score(subgroup_labels, subgroup_predictions, zero_division=0)\n",
    "    recall = recall_score(subgroup_labels, subgroup_predictions, zero_division=0)\n",
    "    f1 = f1_score(subgroup_labels, subgroup_predictions, zero_division=0)\n",
    "    fpr, fnr = compute_fpr_fnr(subgroup_labels, subgroup_predictions)\n",
    "\n",
    "    subgroup_metrics[col] = {\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"False Positive Rate\": fpr,\n",
    "        \"False Negative Rate\": fnr,\n",
    "    }\n",
    "\n",
    "# Display subgroup metrics\n",
    "print(\"\\nSubgroup Analysis Results:\")\n",
    "for col, metrics in subgroup_metrics.items():\n",
    "    print(f\"\\nSubgroup: {col.capitalize()}\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.2f}\")\n",
    "\n",
    "# Compute Disparate Impact Ratio\n",
    "reference_group = \"white\"  # Adjust to the appropriate reference group in your dataset\n",
    "reference_group_data = identity_comments[identity_comments[reference_group] > 0]\n",
    "reference_group_labels = (\n",
    "    reference_group_data[\"target\"].apply(lambda x: 1 if x >= 0.5 else 0).values\n",
    ")\n",
    "reference_group_sequences = tokenizer.texts_to_sequences(\n",
    "    reference_group_data[\"comment_text\"].values\n",
    ")\n",
    "reference_group_padded = pad_sequences(reference_group_sequences, maxlen=max_len)\n",
    "reference_group_raw_predictions = lstm_model.predict(reference_group_padded)\n",
    "reference_group_predictions = (\n",
    "    reference_group_raw_predictions[:, class_indices[\"insult\"]] > 0.5\n",
    ").astype(int)\n",
    "reference_group_rate = reference_group_predictions.mean()\n",
    "\n",
    "dir_metrics = {}\n",
    "for col in identity_columns:\n",
    "    subgroup_data = identity_comments[identity_comments[col] > 0]\n",
    "    subgroup_raw_predictions = lstm_model.predict(\n",
    "        pad_sequences(\n",
    "            tokenizer.texts_to_sequences(subgroup_data[\"comment_text\"].values),\n",
    "            maxlen=max_len,\n",
    "        )\n",
    "    )\n",
    "    subgroup_predictions = (\n",
    "        subgroup_raw_predictions[:, class_indices[\"insult\"]] > 0.5\n",
    "    ).astype(int)\n",
    "    subgroup_rate = subgroup_predictions.mean()\n",
    "    dir_metrics[col] = (\n",
    "        subgroup_rate / reference_group_rate if reference_group_rate > 0 else 0\n",
    "    )\n",
    "\n",
    "print(\"\\nDisparate Impact Ratio:\")\n",
    "for col, ratio in dir_metrics.items():\n",
    "    print(f\"{col.capitalize()}: {ratio:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
